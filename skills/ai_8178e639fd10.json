{
  "id": "ai_8178e639fd10",
  "category": "AI",
  "title": "7.0. lora improvements in fine tuning",
  "description": "# 7.0. LoRA Improvements in fine-tuning\n\n{{#include ../../banners/hacktricks-training.md}}\n\n## LoRA Improvements\n\n> [!TIP]\n> The use of **LoRA reduce a lot the computation** needed to **fine tune** already trained models.\n\nLoRA makes it possible to fine-tune **large models** efficiently by only changing a **small part** of the model. It reduces the number of parameters you need to train, saving **memory** and **computational resources**. This is because:\n\n1. **Reduces the Number of Trainable Par",
  "payloads": [
    "# 7.0. LoRA Improvements in fine-tuning",
    "{{#include ../../banners/hacktricks-training.md}}",
    "## LoRA Improvements",
    "> [!TIP]",
    "> The use of **LoRA reduce a lot the computation** needed to **fine tune** already trained models.",
    "LoRA makes it possible to fine-tune **large models** efficiently by only changing a **small part** of the model. It reduces the number of parameters you need to train, saving **memory** and **computational resources**. This is because:",
    "1. **Reduces the Number of Trainable Parameters**: Instead of updating the entire weight matrix in the model, LoRA **splits** the weight matrix into two smaller matrices (called **A** and **B**). This makes training **faster** and requires **less memory** because fewer parameters need to be updated.",
    "1. This is because instead of calculating the complete weight update of a layer (matrix), it approximates it to a product of 2 smaller matrices reducing the update to calculate:\\",
    "<figure><img src=\"../../images/image (9) (1).png\" alt=\"\"><figcaption></figcaption></figure>",
    "2. **Keeps Original Model Weights Unchanged**: LoRA allows you to keep the original model weights the same, and only updates the **new small matrices** (A and B). This is helpful because it means the model\u2019s original knowledge is preserved, and you only tweak what's necessary.",
    "3. **Efficient Task-Specific Fine-Tuning**: When you want to adapt the model to a **new task**, you can just train the **small LoRA matrices** (A and B) while leaving the rest of the model as it is. This is **much more efficient** than retraining the entire model.",
    "4. **Storage Efficiency**: After fine-tuning, instead of saving a **whole new model** for each task, you only need to store the **LoRA matrices**, which are very small compared to the entire model. This makes it easier to adapt the model to many tasks without using too much storage.",
    "In order to implemente LoraLayers instead of Linear ones during a fine tuning, this code is proposed here [https://github.com/rasbt/LLMs-from-scratch/blob/main/appendix-E/01_main-chapter-code/appendix-E.ipynb](https://github.com/rasbt/LLMs-from-scratch/blob/main/appendix-E/01_main-chapter-code/appendix-E.ipynb):",
    "```python",
    "import math"
  ],
  "source": "HackTricks",
  "references": [
    "/workspaces/hunter-skill/hacktricks/src/AI/AI-llm-architecture/7.0.-lora-improvements-in-fine-tuning.md"
  ]
}